import re
from google import genai
from google.genai import types
import utils
import core_rfi 
<<<<<<< HEAD

# --- PROMPTS ---
PROMPTS = {
    'structure_extraction': """
[System: Thinking Level MINIMAL]
ë‹¹ì‹ ì€ ë¬¸ì„œ êµ¬ì¡° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì œê³µëœ íŒŒì¼ì˜ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ **ë¬¸ì„œì˜ ëª©ì°¨(Table of Contents)**ì™€ **í•µì‹¬ êµ¬ì¡°**ë¥¼ Markdown í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•˜ì‹­ì‹œì˜¤.

[ìš”êµ¬ì‚¬í•­]
1. ë¬¸ì„œì˜ ê³„ì¸µ êµ¬ì¡°(#, ##, ###)ë¥¼ ì›ë³¸ê³¼ ìµœëŒ€í•œ ë™ì¼í•˜ê²Œ ìœ ì§€í•˜ì‹­ì‹œì˜¤.
2. ê° ì±•í„°ì˜ ì œëª©ì„ ê·¸ëŒ€ë¡œ ì‚´ë¦¬ì‹­ì‹œì˜¤.
3. ë‚´ìš©(ë³¸ë¬¸)ì€ ì œì™¸í•˜ê³ , ì˜¤ì§ **êµ¬ì¡°(ë¼ˆëŒ€)**ë§Œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤.
""",
    'report_system': """
ë‹¹ì‹ ì€ **êµ­ë‚´ ìµœì •ìƒê¸‰ PEF/VC ìˆ˜ì„ ì‹¬ì‚¬ì—­**ì…ë‹ˆë‹¤.
[ëŒ€ìƒ ê¸°ì—…]ì— ëŒ€í•œ íˆ¬ìë¥¼ ìŠ¹ì¸ë°›ê¸° ìœ„í•´ íˆ¬ì‹¬ìœ„ ìœ„ì›ë“¤ì„ ì„¤ë“í•  ìˆ˜ ìˆëŠ” **'íˆ¬ìì‹¬ì‚¬ë³´ê³ ì„œ(Investment Memorandum)'**ë¥¼ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤.

[ì‘ì„± ì›ì¹™ - Word ëª¨ë“œ]
1. **ë¶„ì„ íƒœë„ (ìµœìš°ì„ )**: ì œê³µëœ ìë£Œë“¤ì€ íšŒì‚¬ë‚˜ ìë¬¸ì‚¬ê°€ ì‘ì„±í•œ í™ë³´ì„± ìë£Œì„ì„ ê°ì•ˆí•˜ì—¬, **ìµœëŒ€í•œ ê°ê´€ì ì´ê³  ë³´ìˆ˜ì ì¸ íƒœë„**ë¡œ ë¶„ì„í•˜ì„¸ìš”. ì¥ë°‹ë¹› ì „ë§ì€ ë°°ì œí•˜ê³ , ë¦¬ìŠ¤í¬ì™€ í•˜ë°© ìš”ì¸ì„ ë¹„íŒì ìœ¼ë¡œ ê²€í† í•´ì•¼ í•©ë‹ˆë‹¤.
2. **ìƒì„¸ ì‘ì„±**: ì œê³µëœ [ë¶„ì„ ë°ì´í„°]ì˜ **ëª¨ë“  í˜ì´ì§€**ë¥¼ ê¼¼ê¼¼íˆ ë¶„ì„í•˜ì—¬, ë‚´ìš©ì„ ì¶•ì•½í•˜ì§€ ë§ê³  **ìµœëŒ€í•œ ìƒì„¸í•˜ê²Œ** ì‘ì„±í•˜ì„¸ìš”. êµ¬ì²´ì ì¸ ìˆ˜ì¹˜(ë§¤ì¶œì•¡, ì˜ì—…ì´ìµë¥ , CAGR ë“±)ë¥¼ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”.
3. **ì„œìˆ  ë°©ì‹**: ê°€ë…ì„±ì„ ìœ„í•´ **ê°œì¡°ì‹(Bullet points)**ì„ ì ê·¹ í™œìš©í•˜ë˜, ë‹¨ìˆœ ë‚˜ì—´ì´ ì•„ë‹Œ ë…¼ë¦¬ì  ì—°ê²°ì´ ìˆëŠ” ë¬¸ì¥í˜• ê°œì¡°ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”. ì „ë¬¸ ë¹„ì¦ˆë‹ˆìŠ¤ ìš©ì–´(EBITDA, Valuation, IRR, MoIC, Downside protection ë“±)ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•˜ì„¸ìš”.
4. **í‘œ(Table)**: ì›ë³¸ ë°ì´í„°ì˜ ì¬ë¬´ ìˆ˜ì¹˜ë‚˜ ë¹„êµ ìë£ŒëŠ” Markdown Tableë¡œ ë³€í™˜í•˜ì—¬ ì‚½ì…í•˜ì„¸ìš”.
5. **ì¶œì²˜ í‘œê¸°**: ë°ì´í„° ì¸ìš© ì‹œ ë°”ë¡œ ì•„ë˜ì— "Source : [ë¬¸ì„œì˜ ì‹¤ì œ ì œëª©] (p.[í˜ì´ì§€])"ë¥¼ ëª…ì‹œí•˜ì„¸ìš”.
6. **í—¤ë” ê¸ˆì§€**: 'ìˆ˜ì‹ :', 'ë°œì‹ :', 'ì‘ì„±ì¼:' ë“±ì˜ ë³´ê³ ì„œ ê°œìš” ë©”íƒ€ë°ì´í„°ëŠ” ì‘ì„±í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
""",
    'ppt_system': """
ë‹¹ì‹ ì€ **í”„ë ˆì  í…Œì´ì…˜ ì „ë¬¸ê°€**ì´ì **ê¹ê¹í•œ íˆ¬ì ì‹¬ì‚¬ì—­**ì…ë‹ˆë‹¤.
[ì‘ì„± ì›ì¹™ - PPT ëª¨ë“œ]
1. **ë¶„ì„ íƒœë„**: ì œê³µëœ ìë£Œê°€ íšŒì‚¬ ì¸¡ ì£¼ì¥ì„ì„ ì¸ì§€í•˜ê³ , **ê°ê´€ì ì´ê³  ë³´ìˆ˜ì ì¸ ê´€ì **ì—ì„œ í•µì‹¬ ë‚´ìš©ì„ ìš”ì•½í•˜ì„¸ìš”. ê³¼ì¥ëœ í‘œí˜„ì€ ê±¸ëŸ¬ë‚´ê³  íŒ©íŠ¸ ìœ„ì£¼ë¡œ êµ¬ì„±í•˜ì„¸ìš”.
2. **êµ¬ì¡°ì  í¬ë§·íŒ…**: # (ê°„ì§€), ## (ìŠ¬ë¼ì´ë“œ ì œëª©), - (ë‚´ìš©) êµ¬ì¡° ì¤€ìˆ˜.
3. **ë‚´ìš© ì‘ì„±**: ì„œìˆ í˜• ê¸ˆì§€, í•µì‹¬ í‚¤ì›Œë“œ ìœ„ì£¼ì˜ ë‹¨ë¬¸(ê°œì¡°ì‹) ì‘ì„±.
""",
    # [NEW] Custom ëª¨ë“œ ì „ìš© (ì„œì‹ ë³µì œ)
    'custom_system': """
ë‹¹ì‹ ì€ **ë¬¸ì„œ ì‘ì„± ë° í¸ì§‘ ì „ë¬¸ê°€**ì…ë‹ˆë‹¤.
ì‚¬ìš©ìê°€ ì œê³µí•œ **[ë¬¸ì„œ êµ¬ì¡°(Format)]**ë¥¼ ì™„ë²½í•˜ê²Œ ì¤€ìˆ˜í•˜ë©´ì„œ, **[ë¶„ì„ ë°ì´í„°(Raw Data)]**ì˜ ë‚´ìš©ìœ¼ë¡œ ë³¸ë¬¸ì„ ì±„ì›Œ ë„£ìœ¼ì‹­ì‹œì˜¤.

[ì‘ì„± ì›ì¹™ - Custom Mode]
1. **êµ¬ì¡° ì ˆëŒ€ ì¤€ìˆ˜**: ì œê³µëœ [ë¬¸ì„œ êµ¬ì¡°]ì˜ ëª©ì°¨(Header)ì™€ ìˆœì„œë¥¼ **í† ì”¨ í•˜ë‚˜ ë°”ê¾¸ì§€ ë§ê³  ê·¸ëŒ€ë¡œ ìœ ì§€**í•˜ì‹­ì‹œì˜¤. ì„ì˜ë¡œ ëª©ì°¨ë¥¼ ì¶”ê°€í•˜ê±°ë‚˜ ì‚­ì œí•˜ëŠ” ê²ƒì€ ê¸ˆì§€ë©ë‹ˆë‹¤.
2. **Context-Aware Filling**: ê° ì±•í„° ì œëª©(Header)ì´ ì˜ë„í•˜ëŠ” ë°”ë¥¼ íŒŒì•…í•˜ê³ , [ë¶„ì„ ë°ì´í„°]ì—ì„œ ê°€ì¥ ì ì ˆí•œ ë‚´ìš©ì„ ì°¾ì•„ ì„œìˆ í•˜ì‹­ì‹œì˜¤.
3. **ë¹ˆì¹¸ ì±„ìš°ê¸°**: ë§Œì•½ ë°ì´í„°ì— í•´ë‹¹ ì±•í„°ì™€ ê´€ë ¨ëœ ë‚´ìš©ì´ ì—†ë‹¤ë©´, ì–µì§€ë¡œ ì§€ì–´ë‚´ì§€ ë§ê³  "*(í•´ë‹¹ ë‚´ìš© í™•ì¸ ë¶ˆê°€)*"ë¼ê³  í‘œì‹œí•˜ì‹­ì‹œì˜¤.
4. **ìŠ¤íƒ€ì¼**: ì›ë³¸ ì„œì‹ì˜ íë¦„ì„ ë”°ë¥´ë˜, ë‚´ìš©ì€ ì „ë¬¸ì ì´ê³  ê°ê´€ì ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ í†¤ìœ¼ë¡œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
"""
}

TEMPLATE_STRUCTURES = {
    'simple_review': """# 1. Executive Summary
   - ëŒ€ìƒ ê¸°ì—… ìš”ì•½
   - ì£¼ìš” íˆ¬ì ì¡°ê±´

# 2. íšŒì‚¬ í˜„í™©
   - ì„¤ë¦½ ë° ì—°í˜
   - ì£¼ìš” ì‚¬ì—… í˜„í™©

# 3. ì£¼ìš” ë™í–¥ ë° ì´ìŠˆ
   - ìµœê·¼ ì£¼ìš” ê³„ì•½
   - ìµœê·¼ ì£¼ìš” ë‰´ìŠ¤

# 4. ì¬ë¬´ ë° ì£¼ê°€ ë¶„ì„
   - ìš”ì•½ ì¬ë¬´ìƒíƒœ (ìµœê·¼ 3ë…„ ë§¤ì¶œ/ì´ìµ, ìì‚°/ë¶€ì±„ í˜„í™©)
   - (í•„ìš”ì‹œ) ì£¼ê°€ ì¶”ì´ ë° ê±°ë˜ëŸ‰ ë¶„ì„

# 5. ì¢…í•© ì˜ê²¬
   - íˆ¬ì ë¦¬ìŠ¤í¬ ì ê²€
   - ìµœì¢… ì˜ê²¬""",
    'rfi': "[RFI ëª¨ë“œ] ìë™ ìƒì„±ë©ë‹ˆë‹¤.",
    'investment': """# 1. íˆ¬ìë‚´ìš© (Executive Summary)
# 2. íšŒì‚¬í˜„í™©
# 3. ì‹œì¥ë¶„ì„
# 4. ì‚¬ì—…ë¶„ì„
# 5. íˆ¬ì íƒ€ë‹¹ì„±
# 6. ë¦¬ìŠ¤í¬ ë¶„ì„
# 7. ì¢…í•©ì˜ê²¬""",
    'im': "# 1. Highlights\n# 2. Company\n# 3. Market\n# 4. Product\n# 5. Financial",
    'management': "# 1. ê°œìš”\n# 2. í˜„í™©\n# 3. ì´ìŠˆ\n# 4. íšŒìˆ˜",
    'presentation': """# 1. Executive Summary
## íˆ¬ì ê°œìš”
## í•µì‹¬ íˆ¬ì í¬ì¸íŠ¸
## ì£¼ìš” íˆ¬ì ì¡°ê±´

# 2. Market & Business
## ì‹œì¥ ê·œëª¨ ë° ì„±ì¥ì„±
## ê²½ìŸ í˜„í™©
## ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸
## í•µì‹¬ ê¸°ìˆ 

# 3. Financials & Valuation
## ê³¼ê±° ì¬ë¬´ ì‹¤ì 
## ì¶”ì • ì†ìµ
## ê°€ì¹˜í‰ê°€ ë° íšŒìˆ˜ ì „ëµ

# 4. Risk & Opinion
## ì£¼ìš” ë¦¬ìŠ¤í¬ ë° í—·ì§€ ë°©ì•ˆ
## ì¢…í•© íˆ¬ìì˜ê²¬""",
    'custom': ""
}
=======
import prompts
>>>>>>> b5499fc08ff2379c3bc3f5f3545d80550de1327c

def get_client(api_key):
    return genai.Client(api_key=api_key)

def extract_structure(api_key, structure_file):
    try:
        client = get_client(api_key)
        file_text = utils.parse_uploaded_file(structure_file, api_key=api_key)
        prompt = f"{prompts.LOGIC_PROMPTS['structure_extraction']}\n[íŒŒì¼ ë‚´ìš©]\n{file_text[:15000]}"
        resp = client.models.generate_content(model="gemini-3-flash-preview", contents=prompt)
        return resp.text
    except Exception as e:
        return f"êµ¬ì¡° ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}"

def parse_all_files(uploaded_files, read_content=True, api_key=None):
    """íŒŒì¼ ëª©ë¡ íŒŒì‹± (OCR ì§€ì›)

    Args:
        uploaded_files: ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡
        read_content: ë‚´ìš© ì½ê¸° ì—¬ë¶€
        api_key: Google API í‚¤ (PDF OCRìš©)
    """
    all_text = ""
    file_list_str = ""
    if uploaded_files:
        for file in uploaded_files:
            file_list_str += f"- {file.name}\n"
            if read_content:
                parsed = utils.parse_uploaded_file(file, api_key=api_key)
                all_text += parsed

    if not read_content:
        all_text = "(RFI ëª¨ë“œ: ë‚´ìš©ì„ ì½ì§€ ì•ŠìŒ)"

    return all_text, file_list_str

def get_default_structure(template_key):
    return prompts.TEMPLATE_STRUCTURES.get(template_key, "")

def generate_report_stream(api_key, model_name, inputs, thinking_level, file_context):
    client = get_client(api_key)
    template_opt = inputs['template_option']
    structure_text = inputs['structure_text']
    
    # [RFI Mode]
    if template_opt == 'rfi':
        stream = core_rfi.generate_rfi_stream(api_key, model_name, inputs, thinking_level)
        for chunk in stream:
            yield chunk
        return
    
    # [Sequential Generation Strategy]
    # 1. Split structure into chapters to generate long, detailed reports
    # Regex splits by headers starting with # (e.g., # 1. Overview)
    sections = re.split(r'(?=^# )', structure_text, flags=re.MULTILINE)
    sections = [s for s in sections if s.strip()]
    
    # If no sections found (e.g. custom without headers), treat as one block
    if not sections:
        sections = [structure_text]

<<<<<<< HEAD
    for i, section_content in enumerate(sections):
        section_title = section_content.split('\n')[0].replace('#', '').strip()
        
        # Determine System Instruction based on Mode
        if template_opt == 'presentation':
            base_system = PROMPTS['ppt_system']
            task_instruction = f"""
            [í˜„ì¬ ì‘ì—…]
            ì „ì²´ ë°œí‘œìë£Œ ì¤‘ **"{section_title}"** íŒŒíŠ¸ë§Œ ì‘ì„±í•˜ì„¸ìš”.
            ì…ë ¥ëœ [ìŠ¬ë¼ì´ë“œ êµ¬ì¡°]ì˜ í•˜ìœ„ ëª©ì°¨(##)ë¥¼ ìŠ¬ë¼ì´ë“œ ì œëª©ìœ¼ë¡œ ì‚¼ì•„ ë‚´ìš©ì„ êµ¬ì„±í•˜ì„¸ìš”.
            """
        elif template_opt == 'custom':
            base_system = PROMPTS['custom_system']
            task_instruction = f"""
            [í˜„ì¬ ì‘ì—…]
            ì „ì²´ ë¬¸ì„œ ì¤‘ **"{section_title}"** ì±•í„°ë§Œ ì‘ì„±í•˜ì„¸ìš”.
            ì œê³µëœ [ë¬¸ì„œ êµ¬ì¡°]ë¥¼ í† ì”¨ í•˜ë‚˜ í‹€ë¦¬ì§€ ë§ê³  ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ë©° ë‚´ìš©ì„ ì±„ìš°ì‹­ì‹œì˜¤.
            """
        else:
            # Standard Investment Report / Simple Review / IM / Management
            base_system = PROMPTS['report_system']
            
            # Special handling for Simple Review (Summary focus)
            if template_opt == 'simple_review':
                base_system += "\n**ì¤‘ìš”: ì´ ë³´ê³ ì„œëŠ” 5í˜ì´ì§€ ë‚´ì™¸ì˜ 'ìš”ì•½' ë³´ê³ ì„œì…ë‹ˆë‹¤. ì¥í™©í•œ ë‚˜ì—´ë³´ë‹¤ëŠ” í•µì‹¬ ìš”ì•½ê³¼ ê·¼ê±° ìœ„ì£¼ë¡œ ëª…ë£Œí•˜ê²Œ ì„œìˆ í•˜ì„¸ìš”.**"
            
            if inputs['use_diagram']:
                base_system += "\n**ë„ì‹í™”**: ì„¤ëª… ì¤‘ ì‹œê°í™”ê°€ í•„ìš”í•œ í”„ë¡œì„¸ìŠ¤ë‚˜ êµ¬ì¡°ê°€ ìˆë‹¤ë©´ **{{DIAGRAM: ì„¤ëª…}}** íƒœê·¸ë¥¼ ì‚½ì…í•˜ì„¸ìš”."
                
            task_instruction = f"""
            [í˜„ì¬ ì‘ì—…]
            ì „ì²´ ë³´ê³ ì„œ ì¤‘ **"{section_title}"** ì±•í„°ë§Œ ì‘ì„±í•˜ì„¸ìš”.
            ì…ë ¥ëœ [ë¬¸ì„œ êµ¬ì¡°]ì˜ í•˜ìœ„ ëª©ì°¨ë¥¼ ë¹ ì§ì—†ì´ ë‹¤ë£¨ì„¸ìš”.
            """

        # Construct Prompt
=======
    # [PPT Mode]
    if template_opt == 'presentation':
        system_instruction = prompts.LOGIC_PROMPTS['ppt_system']
        main_prompt = f"""
        [System: Thinking Level {thinking_level.upper() if isinstance(thinking_level, str) else 'HIGH'}]
        [ìŠ¬ë¼ì´ë“œ êµ¬ì¡°] {inputs['structure_text']}
        [ë§¥ë½] {inputs['context_text']}
        [ë°ì´í„°] {file_context[:50000]}
        """
        config = types.GenerateContentConfig(
            max_output_tokens=65536,
            temperature=0.7,
            system_instruction=system_instruction
        )

    # [Custom Mode] - ì„œì‹ ë³µì œ
    elif template_opt == 'custom':
        system_instruction = prompts.LOGIC_PROMPTS['custom_system']
>>>>>>> b5499fc08ff2379c3bc3f5f3545d80550de1327c
        main_prompt = f"""
        [System: Thinking Level {thinking_level.upper() if isinstance(thinking_level, str) else 'HIGH'}]
        
        [ì‘ì„±í•  ì±•í„° êµ¬ì¡°]
        {section_content}
        
        [ì „ì²´ ë§¥ë½]
        {inputs['context_text']}
        
        [ë¶„ì„ ë°ì´í„°]
        ì²¨ë¶€ëœ íŒŒì¼ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. ì—†ëŠ” ë‚´ìš©ì€ ì§€ì–´ë‚´ì§€ ë§ê³ , ì¶”ë¡ ì´ í•„ìš”í•˜ë©´ [ì¶”í›„ ì‹¤ì‚¬ í•„ìš”]ë¼ê³  ëª…ì‹œí•˜ì„¸ìš”.
        {file_context[:50000]}
<<<<<<< HEAD
=======
        """
        config = types.GenerateContentConfig(
            max_output_tokens=65536,
            temperature=0.5, # êµ¬ì¡° ì¤€ìˆ˜ë¥¼ ìœ„í•´ ì•½ê°„ ë‚®ì¶¤
            system_instruction=system_instruction
        )

    # [Standard Report Mode]
    else:
        system_instruction = prompts.LOGIC_PROMPTS['report_system']
        if template_opt == 'simple_review':
             system_instruction += "\n**ì¤‘ìš”: 10í˜ì´ì§€ ì´ë‚´ë¡œ í•µì‹¬ë§Œ ìš”ì•½í•˜ì„¸ìš”.**"
        if inputs['use_diagram']:
            system_instruction += "\n**ë„ì‹í™”**: í•„ìš”ì‹œ {{DIAGRAM: ì„¤ëª…}} íƒœê·¸ ì‚½ì…."

        main_prompt = f"""
        [System: Thinking Level {thinking_level.upper() if isinstance(thinking_level, str) else 'HIGH'}]
        [Critical Instruction] Analyze the provided data deeply and step-by-step. Prioritize accuracy and logical consistency.
        [ë¬¸ì„œ êµ¬ì¡°] {inputs['structure_text']}
        [ë§¥ë½] {inputs['context_text']}
        [ë°ì´í„°] {file_context[:50000]}
        """
>>>>>>> b5499fc08ff2379c3bc3f5f3545d80550de1327c
        
        {task_instruction}
        """

        config = types.GenerateContentConfig(
            max_output_tokens=8192,
<<<<<<< HEAD
            temperature=0.7,
            system_instruction=base_system
=======
            temperature=0.3,
            system_instruction=system_instruction
>>>>>>> b5499fc08ff2379c3bc3f5f3545d80550de1327c
        )

        # Generate Stream for this section
        response_stream = client.models.generate_content_stream(
            model=model_name,
            contents=main_prompt,
            config=config
        )
        
        for chunk in response_stream:
            yield chunk
            
        # Add separator between sections
        yield types.GenerateContentResponse(
            candidates=[types.Candidate(
                content=types.Content(parts=[types.Part(text="\n\n")])
            )]
        )

def generate_report_stream_chained(api_key, model_name, inputs, thinking_level, file_context):
    """3ë‹¨ê³„ Chained Promptingìœ¼ë¡œ íˆ¬ìì‹¬ì‚¬ë³´ê³ ì„œ ìƒì„± (í’ˆì§ˆ ìš°ì„ )"""
    client = get_client(api_key)

    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ê³µí†µ)
    system_instruction = prompts.LOGIC_PROMPTS['report_system_base']
    if inputs.get('use_diagram'):
        system_instruction += "\n**ë„ì‹í™”**: í•„ìš”ì‹œ {{DIAGRAM: ì„¤ëª…}} íƒœê·¸ ì‚½ì…."

    # 3ê°œ íŒŒíŠ¸ ì •ì˜ (part_key, title, max_tokens)
    parts = [
        ('report_part1', 'Part 1/3: Executive Summary & Investment Highlights', 65536),
        ('report_part2', 'Part 2/3: Target Company & Market Analysis', 65536),
        ('report_part3', 'Part 3/3: Financials, Valuation, Risk & ì¢…í•©ì˜ê²¬', 65536)
    ]

    accumulated_result = ""

    for part_key, part_title, max_tokens in parts:
        # ì§„í–‰ ìƒí™© ì•Œë¦¼
        status_text = f"\n\n---\n\nğŸ“ **[{part_title}] ìƒì„± ì¤‘...**\n\n"
        yield types.GenerateContentResponse(
            candidates=[types.Candidate(
                content=types.Content(parts=[types.Part(text=status_text)])
            )]
        )

        # ì´ì „ íŒŒíŠ¸ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ í¬í•¨
        prev_context = ""
        if accumulated_result:
            prev_context = f"""
[ì´ì „ ì‘ì„± ë‚´ìš© - ì°¸ê³ ìš©, ì¤‘ë³µ ì‘ì„± ê¸ˆì§€]
{accumulated_result[-20000:]}
"""

        main_prompt = f"""
[System: Thinking Level {thinking_level.upper() if isinstance(thinking_level, str) else 'HIGH'}]
[Critical Instruction] Analyze the provided data deeply and step-by-step. Prioritize accuracy and logical consistency.

{prev_context}

{prompts.LOGIC_PROMPTS[part_key]}

[ë§¥ë½]
{inputs['context_text']}

[ë¶„ì„ ë°ì´í„°]
{file_context[:45000]}
"""

        tools = []
        # Part 2 (ì‹œì¥ ë¶„ì„)ì—ì„œ ì›¹ ê²€ìƒ‰ í™œì„±í™”
        if part_key == 'report_part2':
            tools = [types.Tool(google_search=types.GoogleSearch())]

        config = types.GenerateContentConfig(
            tools=tools,
            max_output_tokens=max_tokens,
            temperature=0.3,
            system_instruction=system_instruction
        )

        part_result = ""
        response_stream = client.models.generate_content_stream(
            model=model_name,
            contents=main_prompt,
            config=config
        )

        for chunk in response_stream:
            if chunk.text:
                part_result += chunk.text
            yield chunk

        accumulated_result += part_result


def refine_report(api_key, model_name, current_text, refine_query):
    client = get_client(api_key)
    refine_prompt = f"""
    ë‹¹ì‹ ì€ ë¬¸ì„œ ìˆ˜ì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
    ì‚¬ìš©ì ìš”ì²­: "{refine_query}"
    ê¸°ì¡´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ **"## ğŸ”„ ì¶”ê°€ ìš”ì²­ ë°˜ì˜"** í•˜ìœ„ì— ë‚´ìš©ì„ ì‘ì„±í•˜ì„¸ìš”.
    [ê¸°ì¡´ ë‚´ìš©] {current_text[:20000]}...
    """
    resp = client.models.generate_content(model=model_name, contents=refine_prompt)
    return resp.text