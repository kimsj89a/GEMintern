from google import genai
from google.genai import types
import utils
import datetime

# --- PROMPTS ---
PROMPTS = {
    'structure_extraction': """
[System: Thinking Level MINIMAL]
ë‹¹ì‹ ì€ ë¬¸ì„œ êµ¬ì¡° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì œê³µëœ íŒŒì¼ì˜ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ **ë¬¸ì„œì˜ ëª©ì°¨(Table of Contents)**ì™€ **í•µì‹¬ êµ¬ì¡°**ë¥¼ Markdown í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•˜ì‹­ì‹œì˜¤.
""",
    'rfi_system': """
ë‹¹ì‹ ì€ íšŒê³„ë²•ì¸ FASíŒ€ì˜ M&A ì‹¤ì‚¬ ì „ë¬¸ ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.
(ê¸°ì¡´ ë‚´ìš© ìœ ì§€...)
""",
    'report_system': """
ë‹¹ì‹ ì€ **êµ­ë‚´ ìµœì •ìƒê¸‰ PEF/VC ìˆ˜ì„ ì‹¬ì‚¬ì—­**ì…ë‹ˆë‹¤. 
[ëŒ€ìƒ ê¸°ì—…]ì— ëŒ€í•œ íˆ¬ìë¥¼ ìŠ¹ì¸ë°›ê¸° ìœ„í•´ íˆ¬ì‹¬ìœ„ ìœ„ì›ë“¤ì„ ì„¤ë“í•  ìˆ˜ ìˆëŠ” **'íˆ¬ìì‹¬ì‚¬ë³´ê³ ì„œ(Investment Memorandum)'**ë¥¼ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤.

[ì‘ì„± ì›ì¹™ - Word ëª¨ë“œ]
1. **í—¤ë” ê¸ˆì§€**: 'ìˆ˜ì‹ :', 'ë°œì‹ :', 'ì‘ì„±ì¼:', 'ëŒ€ìƒ:' ë“±ì˜ ë³´ê³ ì„œ ê°œìš” ë©”íƒ€ë°ì´í„°ë¥¼ ì ˆëŒ€ ì‘ì„±í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
2. **ë¶„ì„ íƒœë„**: ê°ê´€ì ì´ê³  ë³´ìˆ˜ì ì¸ íƒœë„ë¡œ ë¶„ì„í•˜ì„¸ìš”.
3. **ì„œìˆ  ë°©ì‹**: ë…¼ë¦¬ì  ì—°ê²°ì´ ìˆëŠ” ë¬¸ì¥í˜• ê°œì¡°ì‹(Bullet points)ì„ ì‚¬ìš©í•˜ì„¸ìš”.
4. **ê²°ë¡  ì‘ì„± ê·œì¹™ (ì¤‘ìš”)**: 
   - ì¢…í•© ì˜ê²¬ì´ë‚˜ ê²°ë¡  ì±•í„° ì‘ì„± ì‹œ, **"[ìŠ¹ì¸ ê¶Œê³ ]", "[ì¡°ê±´ë¶€ ìŠ¹ì¸]", "Recommendation:" ê°™ì€ ë¼ë²¨ì´ë‚˜ ë§ë¨¸ë¦¬ë¥¼ ì ˆëŒ€ ë¶™ì´ì§€ ë§ˆì‹­ì‹œì˜¤.**
   - ë°”ë¡œ ë‚´ìš©ì„ ì„œìˆ í•˜ì‹­ì‹œì˜¤. (ì˜ˆ: "ë³¸ ê±´ íˆ¬ìëŠ” ~í•œ ì´ìœ ë¡œ íƒ€ë‹¹í•˜ë‹¤ê³  íŒë‹¨ë¨." ì²˜ëŸ¼ ì‘ì„±)
5. **í‘œ/ì¶œì²˜**: Markdown Table ì‚¬ìš©, ì¶œì²˜ ëª…ì‹œ.
""",
    'ppt_system': """
ë‹¹ì‹ ì€ **í”„ë ˆì  í…Œì´ì…˜ ì „ë¬¸ê°€**ì…ë‹ˆë‹¤.
(ê¸°ì¡´ ë‚´ìš© ìœ ì§€...)
"""
}

TEMPLATE_STRUCTURES = {
    'simple_review': """# 1. Executive Summary
   - ëŒ€ìƒ ê¸°ì—… ìš”ì•½
   - ì£¼ìš” íˆ¬ì ì¡°ê±´

# 2. íšŒì‚¬ í˜„í™©
   - ì„¤ë¦½ ë° ì—°í˜
   - ì£¼ìš” ì‚¬ì—… í˜„í™©

# 3. ì£¼ìš” ë™í–¥ ë° ì´ìŠˆ
   - ìµœê·¼ ì£¼ìš” ê³„ì•½
   - ìµœê·¼ ì£¼ìš” ë‰´ìŠ¤

# 4. ì¬ë¬´ ë° ì£¼ê°€ ë¶„ì„
   - ìš”ì•½ ì¬ë¬´ìƒíƒœ (ìµœê·¼ 3ë…„ ë§¤ì¶œ/ì´ìµ, ìì‚°/ë¶€ì±„ í˜„í™©)
   - (í•„ìš”ì‹œ) ì£¼ê°€ ì¶”ì´ ë° ê±°ë˜ëŸ‰ ë¶„ì„

# 5. ì¢…í•© ì˜ê²¬
   - íˆ¬ì ë¦¬ìŠ¤í¬ ì ê²€
   - ìµœì¢… ì˜ê²¬""",
    'rfi': "[RFI ëª¨ë“œ]",
    'investment': """# 1. íˆ¬ìë‚´ìš© (Executive Summary)
# 2. íšŒì‚¬í˜„í™©
# 3. ì‹œì¥ë¶„ì„
# 4. ì‚¬ì—…ë¶„ì„
# 5. íˆ¬ì íƒ€ë‹¹ì„±
# 6. ë¦¬ìŠ¤í¬ ë¶„ì„
# 7. ì¢…í•©ì˜ê²¬""",
    'im': "# 1. Highlights\n# 2. Company\n# 3. Market\n# 4. Product\n# 5. Financial",
    'management': "# 1. ê°œìš”\n# 2. í˜„í™©\n# 3. ì´ìŠˆ\n# 4. íšŒìˆ˜",
    'presentation': """# 1. Executive Summary
## íˆ¬ì ê°œìš”
## í•µì‹¬ íˆ¬ì í¬ì¸íŠ¸
## ì£¼ìš” íˆ¬ì ì¡°ê±´

# 2. Market & Business
## ì‹œì¥ ê·œëª¨ ë° ì„±ì¥ì„±
## ê²½ìŸ í˜„í™©
## ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸
## í•µì‹¬ ê¸°ìˆ 

# 3. Financials & Valuation
## ê³¼ê±° ì¬ë¬´ ì‹¤ì 
## ì¶”ì • ì†ìµ
## ê°€ì¹˜í‰ê°€ ë° íšŒìˆ˜ ì „ëµ

# 4. Risk & Opinion
## ì£¼ìš” ë¦¬ìŠ¤í¬ ë° í—·ì§€ ë°©ì•ˆ
## ì¢…í•© íˆ¬ìì˜ê²¬""",
    'custom': ""
}

def get_client(api_key):
    return genai.Client(api_key=api_key)

def extract_structure(api_key, structure_file):
    try:
        client = get_client(api_key)
        file_text = utils.parse_uploaded_file(structure_file)
        prompt = f"{PROMPTS['structure_extraction']}\n[íŒŒì¼ ë‚´ìš©]\n{file_text[:15000]}"
        resp = client.models.generate_content(model="gemini-3-flash-preview", contents=prompt)
        return resp.text
    except Exception as e:
        return f"êµ¬ì¡° ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}"

def parse_all_files(uploaded_files):
    all_text = ""
    file_list_str = ""
    if uploaded_files:
        for file in uploaded_files:
            parsed = utils.parse_uploaded_file(file)
            all_text += parsed
            file_list_str += f"- {file.name}\n"
    return all_text, file_list_str

def get_default_structure(template_key):
    return TEMPLATE_STRUCTURES.get(template_key, "")

def generate_report_stream(api_key, model_name, inputs, thinking_level, file_context):
    client = get_client(api_key)
    template_opt = inputs['template_option']
    
    if template_opt == 'rfi':
        system_instruction = PROMPTS['rfi_system']
        uploaded_list = [f.name for f in inputs['uploaded_files']] if inputs['uploaded_files'] else []
        file_list_str = "\n".join([f"- {name}" for name in uploaded_list])
        main_prompt = f"""
        [System: Thinking Level {thinking_level.upper() if isinstance(thinking_level, str) else 'HIGH'}]
        # [ê¸°ì¡´ RFI] {inputs['rfi_existing']}
        # [ì‹ ê·œ ì§ˆë¬¸] {inputs['context_text']}
        [íŒŒì¼ ëª©ë¡] {file_list_str}
        [ì°¸ê³  ë‚´ìš©] {file_context[:30000]}
        """
    elif template_opt == 'presentation':
        system_instruction = PROMPTS['ppt_system']
        main_prompt = f"""
        [System: Thinking Level {thinking_level.upper() if isinstance(thinking_level, str) else 'HIGH'}]
        [ìŠ¬ë¼ì´ë“œ êµ¬ì¡°] {inputs['structure_text']}
        [ë§¥ë½] {inputs['context_text']}
        [ë°ì´í„°] {file_context[:50000]}
        """
    else:
        system_instruction = PROMPTS['report_system']
        if template_opt == 'simple_review':
             system_instruction += "\n**ì¤‘ìš”: 10í˜ì´ì§€ ì´ë‚´ë¡œ í•µì‹¬ë§Œ ìš”ì•½í•˜ì„¸ìš”.**"
        if inputs['use_diagram']:
            system_instruction += "\n**ë„ì‹í™”**: í•„ìš”ì‹œ {{DIAGRAM: ì„¤ëª…}} íƒœê·¸ ì‚½ì…."

        main_prompt = f"""
        [System: Thinking Level {thinking_level.upper() if isinstance(thinking_level, str) else 'HIGH'}]
        [ë¬¸ì„œ êµ¬ì¡°] {inputs['structure_text']}
        [ë§¥ë½] {inputs['context_text']}
        [ë°ì´í„°] {file_context[:50000]}
        """

    tools = []
    if template_opt != 'rfi' and ("ë‰´ìŠ¤" in inputs['structure_text'] or "ë™í–¥" in inputs['structure_text']):
        tools = [types.Tool(google_search=types.GoogleSearch())]

    config = types.GenerateContentConfig(
        tools=tools,
        max_output_tokens=8192,
        temperature=0.2 if template_opt == 'rfi' else 0.7,
        system_instruction=system_instruction
    )

    response_stream = client.models.generate_content_stream(
        model=model_name,
        contents=main_prompt,
        config=config
    )
    for chunk in response_stream:
        yield chunk

def refine_report(api_key, model_name, current_text, refine_query):
    client = get_client(api_key)
    refine_prompt = f"""
    ë‹¹ì‹ ì€ ë¬¸ì„œ ìˆ˜ì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
    ì‚¬ìš©ì ìš”ì²­: "{refine_query}"
    ê¸°ì¡´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ **"## ğŸ”„ ì¶”ê°€ ìš”ì²­ ë°˜ì˜"** í•˜ìœ„ì— ë‚´ìš©ì„ ì‘ì„±í•˜ì„¸ìš”.
    [ê¸°ì¡´ ë‚´ìš©] {current_text[:20000]}...
    """
    resp = client.models.generate_content(model=model_name, contents=refine_prompt)
    return resp.text