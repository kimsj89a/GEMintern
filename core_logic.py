import streamlit as st
from google import genai
from google.genai import types
import utils
import traceback

def process_and_generate(inputs, api_key, model_name, thinking_level, response_container):
    """
    íŒŒì¼ ì²˜ë¦¬ -> í”„ë¡¬í”„íŠ¸ êµ¬ì„± -> Gemini API í˜¸ì¶œ ê³¼ì •ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    ê²°ê³¼ëŠ” response_container(Streamlit placeholder)ì— ìŠ¤íŠ¸ë¦¬ë°ë©ë‹ˆë‹¤.
    """
    client = genai.Client(api_key=api_key)
    full_response = ""

    try:
        # 1. íŒŒì¼ ë‚´ìš© íŒŒì‹±
        all_file_text = ""
        uploaded_files = inputs['uploaded_files']
        
        if uploaded_files:
            st.info(f"ğŸ“‚ íŒŒì¼ {len(uploaded_files)}ê°œ ë¶„ì„ ì¤‘...")
            progress_bar = st.progress(0)
            
            for i, file in enumerate(uploaded_files):
                file_content = utils.parse_uploaded_file(file)
                all_file_text += file_content
                progress_bar.progress((i + 1) / len(uploaded_files))
            
            st.success("íŒŒì¼ ë¶„ì„ ì™„ë£Œ!")
        
        # 2. í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        st.info("ğŸ§  ìƒê° ì •ë¦¬ ì¤‘...")
        system_instruction = "ë‹¹ì‹ ì€ ì „ë¬¸ íˆ¬ì ì‹¬ì‚¬ì—­ì…ë‹ˆë‹¤. ê°ê´€ì ì´ê³  ë³´ìˆ˜ì ì¸ íƒœë„ë¡œ ë¶„ì„í•˜ì„¸ìš”."
        
        # Google Grounding ë„êµ¬ ì„¤ì •
        tools = []
        structure_text = inputs['structure_text']
        if "ë‰´ìŠ¤" in structure_text or "ë™í–¥" in structure_text or inputs['template_key'] == 'simple_review':
            tools = [types.Tool(google_search=types.GoogleSearch())]
            st.info("ğŸ” Google Search ë„êµ¬ í™œì„±í™”ë¨ (ìµœì‹  ì •ë³´ ê²€ìƒ‰)")

        full_prompt = f"""
        {system_instruction}
        [Thinking Level: {thinking_level.upper()}]
        
        [ì‘ì„±í•  ë¬¸ì„œ êµ¬ì¡°] 
        {structure_text}
        
        [ë§¥ë½ ë° ìš”ì²­ì‚¬í•­] 
        {inputs['context_text']}
        
        [ê¸°ì¡´ RFI (í•´ë‹¹ ì‹œ)]
        {inputs['rfi_existing']}
        
        [ì°¸ê³  ë°ì´í„° (íŒŒì¼ ë‚´ìš©)] 
        {all_file_text[:60000]} 
        """ # í† í° ì œí•œ ê³ ë ¤ (í•„ìš”ì‹œ ì¡°ì ˆ)

        # 3. API í˜¸ì¶œ ë° ìŠ¤íŠ¸ë¦¬ë°
        st.info(f"âœ¨ ë¬¸ì„œ ì‘ì„± ì‹œì‘... ({model_name})")
        
        config = types.GenerateContentConfig(
            tools=tools,
            max_output_tokens=8192,
            temperature=0.7
        )

        response = client.models.generate_content_stream(
            model=model_name,
            contents=full_prompt,
            config=config
        )
        
        for chunk in response:
            if chunk.text:
                full_response += chunk.text
                response_container.markdown(full_response + "â–Œ")
        
        response_container.markdown(full_response)
        return full_response

    except Exception as e:
        st.error("ì˜¤ë¥˜ ë°œìƒ!")
        st.code(traceback.format_exc())
        return None