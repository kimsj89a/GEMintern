"""
ì˜¤ë””ì˜¤ ì „ì‚¬ ê¸°ëŠ¥ ë…ë¦½ ëª¨ë“ˆ
Whisper API ë˜ëŠ” Geminië¥¼ ì‚¬ìš©í•œ ìŒì„± íŒŒì¼ í…ìŠ¤íŠ¸ ë³€í™˜
"""
import streamlit as st
import utils_audio

def render_audio_transcription_panel():
    """ì˜¤ë””ì˜¤ ì „ì‚¬ ì „ìš© UI íŒ¨ë„"""
    st.markdown("### ğŸ¤ ì˜¤ë””ì˜¤ ì „ì‚¬ (Audio Transcription)")
    st.markdown("""
        <div style='background-color: #e8f4f8; padding: 15px; border-radius: 8px; margin-bottom: 20px; border-left: 4px solid #0068c9;'>
        <h4 style='margin-top: 0; color: #0068c9;'>ğŸ“‹ ì›Œí¬í”Œë¡œìš°</h4>
        <b>1ë‹¨ê³„:</b> ë¶„Â·ë¬¸ì¥ ë‹¨ìœ„ë¡œ í™”ì êµ¬ë¶„í•˜ì—¬ ì „ì‚¬<br/>
        <b>2ë‹¨ê³„:</b> ì „ì‚¬ ë‚´ìš©ì„ ì£¼ì œë³„ë¡œ ë¬¶ì–´ì„œ í‘œì‹œ & í¸ì§‘<br/>
        <b>3ë‹¨ê³„:</b> AI í›„ì²˜ë¦¬ (ì„ íƒ) - Summary/Q&A/ë°œí‘œìë£Œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        <hr style='margin: 10px 0; border: none; border-top: 1px solid #ccc;'>
        <small>âœ“ Whisper & Gemini ì§€ì› | âœ“ íƒ€ì„ìŠ¤íƒ¬í”„ & í™”ì êµ¬ë¶„ | âœ“ ì£¼ì œë³„ ìë™ ê·¸ë£¹í•‘</small>
        </div>
    """, unsafe_allow_html=True)

    # ============================================
    # 1ë‹¨ê³„: ì „ì‚¬ ì„¤ì • ë° ì‹¤í–‰
    # ============================================
    st.markdown("---")
    st.markdown("## 1ï¸âƒ£ ì „ì‚¬ ì„¤ì •")

    # ì „ì‚¬ ì—”ì§„ ì„ íƒ
    col_engine1, col_engine2 = st.columns([2, 1])
    with col_engine1:
        transcription_engine = st.selectbox(
            "ğŸ¤– ì „ì‚¬ ì—”ì§„ ì„ íƒ",
            options=[
                ("Google Gemini", "gemini"),
                ("OpenAI Whisper", "whisper")
            ],
            format_func=lambda x: x[0],
            help="Whisper: íƒ€ì„ìŠ¤íƒ¬í”„ ì§€ì›, ë†’ì€ ì •í™•ë„ | Gemini: ë¹ ë¥¸ ì²˜ë¦¬, ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›",
            key="audio_transcription_engine"
        )

    # API í‚¤ ì…ë ¥ - ì„ íƒëœ ì—”ì§„ì— ë”°ë¼ ë³€ê²½
    query_params = st.query_params

    if transcription_engine[1] == "whisper":
        cached_key = query_params.get("openai_api_key", "")
        if isinstance(cached_key, list):
            cached_key = cached_key[0]

        col1, col2 = st.columns([3, 1])
        with col1:
            api_key = st.text_input(
                "OpenAI API Key",
                value=cached_key,
                type="password",
                placeholder="sk-...",
                key="audio_openai_key"
            )
        with col2:
            st.write("")
            st.write("")
            save_key = st.checkbox("ğŸ”‘ í‚¤ ì €ì¥", value=bool(cached_key), key="audio_save_key")

        if save_key and api_key:
            st.query_params["openai_api_key"] = api_key
        elif not save_key and "openai_api_key" in st.query_params:
            del st.query_params["openai_api_key"]

    else:  # Gemini
        cached_key = query_params.get("gemini_api_key", "")
        if isinstance(cached_key, list):
            cached_key = cached_key[0]

        col1, col2 = st.columns([3, 1])
        with col1:
            api_key = st.text_input(
                "Gemini API Key",
                value=cached_key,
                type="password",
                placeholder="AI...",
                key="audio_gemini_key"
            )
        with col2:
            st.write("")
            st.write("")
            save_key = st.checkbox("ğŸ”‘ í‚¤ ì €ì¥", value=bool(cached_key), key="audio_save_gemini_key")

        if save_key and api_key:
            st.query_params["gemini_api_key"] = api_key
        elif not save_key and "gemini_api_key" in st.query_params:
            del st.query_params["gemini_api_key"]

    # íŒŒì¼ ì—…ë¡œë“œ
    uploaded_audio = st.file_uploader(
        "ğŸµ ì˜¤ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ (MP3, WAV, M4A ë“±)",
        type=['mp3', 'wav', 'm4a', 'mp4', 'mpeg', 'mpga', 'webm', 'ogg', 'flac'],
        key="audio_file_uploader"
    )

    # ì „ì‚¬ ì˜µì…˜ (í™•ì¥ ê°€ëŠ¥í•œ ì„¹ì…˜ìœ¼ë¡œ ë³€ê²½)
    with st.expander("âš™ï¸ ì „ì‚¬ ì˜µì…˜ (ê³ ê¸‰)", expanded=False):
        col1, col2 = st.columns(2)

        with col1:
            st.markdown("**ê¸°ë³¸ ì„¤ì •**")
            include_timestamps = st.checkbox(
                "â±ï¸ íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨ [mm:ss]",
                value=True,
                help="ê° ë¬¸ë‹¨ì— ì‹œì‘-ì¢…ë£Œ ì‹œê°„ í‘œì‹œ",
                key="audio_timestamps"
            )

            remove_fillers = st.checkbox(
                "ğŸ§¹ ì¶”ì„ìƒˆ ìë™ ì œê±°",
                value=True,
                help="'ì•„', 'ìŒ', 'ê·¸' ë“± ë¶ˆí•„ìš”í•œ í‘œí˜„ ì œê±°",
                key="audio_remove_fillers"
            )

            chunk_minutes = st.slider(
                "ğŸ“¦ ê¸´ íŒŒì¼ ë¶„í•  ë‹¨ìœ„ (ë¶„)",
                min_value=5,
                max_value=30,
                value=10,
                step=5,
                help="FFmpeg ì„¤ì¹˜ ì‹œ ìë™ ë¶„í•  (ë¯¸ì„¤ì¹˜ ì‹œ ì „ì²´ ì²˜ë¦¬)",
                key="audio_chunk_minutes"
            )

        with col2:
            st.markdown("**ê³ ê¸‰ ì„¤ì •**")

            # í™”ì ë¶„ë¦¬ (ê³ ê¸‰ ê¸°ëŠ¥ - HF_TOKEN í•„ìš”)
            do_diarization = st.checkbox(
                "ğŸ­ í™”ì ë¶„ë¦¬ ì‹œë„ (ì‹¤í—˜ì )",
                value=False,
                help="HuggingFace Token í™˜ê²½ë³€ìˆ˜ í•„ìš” (HF_TOKEN)",
                key="audio_diarization"
            )

        # FFmpeg ì„¤ì¹˜ í™•ì¸
        has_ffmpeg = utils_audio._has_ffmpeg()
        if not has_ffmpeg:
            if transcription_engine[1] == "gemini":
                st.info("â„¹ï¸ FFmpegê°€ ì—†ì–´ë„ Gemini ì—”ì§„ì€ ëŒ€ìš©ëŸ‰ íŒŒì¼ì„ ìë™ìœ¼ë¡œ ë¶„í•  ì²˜ë¦¬(Batch)í•©ë‹ˆë‹¤.")
            else:
                st.warning("âš ï¸ FFmpegê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸´ íŒŒì¼ ë¶„í•  ë° í˜•ì‹ ë³€í™˜ì´ ì œí•œë©ë‹ˆë‹¤.")

    # ì „ì‚¬ ì‹¤í–‰ ë²„íŠ¼
    if st.button("ğŸš€ ì „ì‚¬ ì‹œì‘", use_container_width=True, type="primary", key="audio_transcribe_btn"):
        if not api_key:
            st.error("âš ï¸ API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”")
        elif not uploaded_audio:
            st.error("âš ï¸ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”")
        else:
            engine_name = "Whisper" if transcription_engine[1] == "whisper" else "Gemini"
            with st.spinner(f"ğŸ§ {engine_name}ë¡œ ì˜¤ë””ì˜¤ ì „ì‚¬ ì¤‘... (íŒŒì¼ í¬ê¸°ì— ë”°ë¼ ìˆ˜ ë¶„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)"):
                try:
                    # ì‹¤ì‹œê°„ ê²°ê³¼ í‘œì‹œë¥¼ ìœ„í•œ ì»¨í…Œì´ë„ˆ
                    progress_container = st.container()
                    with progress_container:
                        st.info("ğŸ”„ ìˆœì°¨ì  ì²˜ë¦¬ ì¤‘... (ì „ì‚¬ -> ìš”ì•½)")
                        col_res1, col_res2 = st.columns(2)
                        with col_res1:
                            st.markdown("### ğŸ“œ ì‹¤ì‹œê°„ ì „ì‚¬")
                            transcription_placeholder = st.empty()
                        with col_res2:
                            st.markdown("### ğŸ“ ì‹¤ì‹œê°„ íšŒì˜ë¡")
                            summary_placeholder = st.empty()

                                        def _render_chunk_views(chunks):
                        transcript_parts = []
                        summary_parts = []
                        for i, c in enumerate(chunks, 1):
                            transcript_parts.append(f"#### Chunk {i}
{c.get('text','')}")
                            if c.get('summary'):
                                summary_parts.append(f"#### Chunk {i}
{c['summary']}")
                            else:
                                summary_parts.append(f"#### Chunk {i}
(Summary pending...)")
                        return "

---

".join(transcript_parts), "

---

".join(summary_parts)

                    full_transcript = ""
                    full_summary = ""
                    chunk_results = []
                    
                    # Generatorë¥¼ í†µí•´ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬
                    for chunk_text in utils_audio.transcribe_audio(
                        uploaded_file=uploaded_audio,
                        api_key=api_key,
                        language="ko",
                        chunk_seconds=chunk_minutes * 60,
                        do_diarization=do_diarization if transcription_engine[1] == "whisper" else False,  # GeminiëŠ” í™”ì ë¶„ë¦¬ ë¯¸ì§€ì›
                        include_timestamps=include_timestamps,  # Geminië„ íƒ€ì„ìŠ¤íƒ¬í”„ ì§€ì›í•˜ë„ë¡ ë³€ê²½
                        remove_fillers=remove_fillers,
                        gpt_mode=None,  # GPT í›„ì²˜ë¦¬ ì œê±° (ë‚˜ì¤‘ì— ë³„ë„ë¡œ ìˆ˜í–‰)
                        gpt_model=None,
                        engine=transcription_engine[1],  # whisper ë˜ëŠ” gemini
                        gemini_model="gemini-2.0-flash-exp"  # Gemini ëª¨ë¸
                    ):
                        # 1. ??? ???????? ????? (??? ????? ???)
                        chunk_results.append({"text": chunk_text, "summary": None})
                        transcript_md, summary_md = _render_chunk_views(chunk_results)
                        transcription_placeholder.markdown(transcript_md)
                        summary_placeholder.markdown(summary_md)
                        full_transcript += chunk_text + "

"

                        # 2. í•´ë‹¹ ì²­í¬ì— ëŒ€í•œ ìš”ì•½ ìƒì„± (ìˆœì°¨ì  ìš”ì•½)
                        try:
                            auto_model = "gemini-2.0-flash-exp" if transcription_engine[1] == "gemini" else "gpt-4o-mini"
                            auto_api_type = "gemini" if transcription_engine[1] == "gemini" else "openai"
                            
                            chunk_summary = utils_audio._gpt_postprocess(
                                raw_text=chunk_text,
                                mode="meeting_summary",
                                model=auto_model,
                                api_key=api_key,
                                api_type=auto_api_type
                            )
                            chunk_results[-1]["summary"] = chunk_summary
                            transcript_md, summary_md = _render_chunk_views(chunk_results)
                            transcription_placeholder.markdown(transcript_md)
                            summary_placeholder.markdown(summary_md)
                            full_summary += chunk_summary + "

"
                        except Exception as e:
                            full_summary += f"\n[ìš”ì•½ ì‹¤íŒ¨: {e}]\n"

                    # ê²°ê³¼ ì €ì¥
                    st.session_state['transcription_result'] = full_transcript
                    st.session_state['gpt_processed_result'] = full_summary
                    st.session_state['transcription_api_key'] = api_key  # API í‚¤ ì €ì¥ (í›„ì²˜ë¦¬ìš©)
                    st.session_state['transcription_engine'] = transcription_engine[1]  # ì‚¬ìš©ëœ ì—”ì§„ ì €ì¥

                    st.success(f"âœ… {engine_name} ì „ì‚¬ ì™„ë£Œ!")
                    st.rerun()  # ê²°ê³¼ í‘œì‹œë¥¼ ìœ„í•´ ë¦¬ëŸ°
                except Exception as e:
                    st.error(f"âš ï¸ ì „ì‚¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                finally:
                    # íŒŒì¼ ê°ì²´ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì •ë¦¬ (seekì„ í†µí•´ ìŠ¤íŠ¸ë¦¼ ë¦¬ì…‹)
                    try:
                        uploaded_audio.seek(0)
                    except Exception:
                        pass

    # ============================================
    # 2ë‹¨ê³„: ì „ì‚¬ ê²°ê³¼ í™•ì¸ & í¸ì§‘
    # ============================================
    if 'transcription_result' in st.session_state and st.session_state['transcription_result']:
        st.markdown("---")
        st.markdown("## 2ï¸âƒ£ ì „ì‚¬ ê²°ê³¼")

        # [í™”ì ì´ë¦„ ë³€ê²½ UI]
        with st.expander("ğŸ‘¥ í™”ì ì´ë¦„ ì¼ê´„ ë³€ê²½ (Speaker Renaming)", expanded=True):
            c_find, c_replace, c_btn = st.columns([2, 2, 1])
            with c_find:
                find_text = st.text_input("ì°¾ì„ í…ìŠ¤íŠ¸ (ì˜ˆ: í™”ì 1)", key="spk_find")
            with c_replace:
                replace_text = st.text_input("ë³€ê²½í•  ì´ë¦„ (ì˜ˆ: í™ê¸¸ë™)", key="spk_replace")
            with c_btn:
                st.write("")
                if st.button("ë³€ê²½ ì ìš©", use_container_width=True):
                    if find_text and replace_text:
                        st.session_state['transcription_result'] = st.session_state['transcription_result'].replace(find_text, replace_text)
                        # íšŒì˜ë¡ë„ í•¨ê»˜ ì—…ë°ì´íŠ¸
                        if 'gpt_processed_result' in st.session_state:
                            st.session_state['gpt_processed_result'] = st.session_state['gpt_processed_result'].replace(find_text, replace_text)
                        st.success("ì ìš© ì™„ë£Œ!")
                        st.rerun()

        result_text = st.session_state['transcription_result']

        # ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° (íƒ­ìœ¼ë¡œ ë³€ê²½)
        tab_preview, tab_edit = st.tabs(["ğŸ“„ ë¯¸ë¦¬ë³´ê¸°", "âœï¸ í¸ì§‘"])

        with tab_preview:
            st.markdown(result_text)

        with tab_edit:
            edited_text = st.text_area(
                "ì „ì‚¬ëœ í…ìŠ¤íŠ¸ (í¸ì§‘ ê°€ëŠ¥)",
                value=result_text,
                height=500,
                key="audio_result_text",
                label_visibility="collapsed"
            )
            # í¸ì§‘ ë‚´ìš© ì €ì¥ ë²„íŠ¼
            if st.button("ğŸ’¾ í¸ì§‘ ë‚´ìš© ì €ì¥", use_container_width=True):
                st.session_state['transcription_result'] = edited_text
                st.success("âœ… í¸ì§‘ ë‚´ìš©ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.rerun()

        # ============================================
        # 3ë‹¨ê³„: AI í›„ì²˜ë¦¬ (ì„ íƒì‚¬í•­)
        # ============================================
        st.markdown("---")
        st.markdown("## 3ï¸âƒ£ AI í›„ì²˜ë¦¬ (ì„ íƒì‚¬í•­)")

        # í›„ì²˜ë¦¬ ì—”ì§„ ì„ íƒ
        col_post1, col_post2 = st.columns([2, 1])

        with col_post1:
            post_engine = st.selectbox(
                "ğŸ¤– í›„ì²˜ë¦¬ ì—”ì§„ ì„ íƒ",
                options=[
                    ("Google Gemini", "gemini"),
                    ("OpenAI GPT", "openai")
                ],
                format_func=lambda x: x[0],
                help="í…ìŠ¤íŠ¸ ì •ë¦¬/ìš”ì•½ì— ì‚¬ìš©í•  AI ì—”ì§„",
                key="audio_post_engine"
            )

        with col_post2:
            if post_engine[1] == "openai":
                post_model = st.selectbox(
                    "ëª¨ë¸ ì„ íƒ",
                    options=[
                        "GPT-5.2-chat-latest",
                        "GPT-5.2",
                        "GPT-5.2 Pro"
                    ],
                    index=0,
                    help="í›„ì²˜ë¦¬ìš© OpenAI ëª¨ë¸",
                    key="audio_post_model_openai"
                )
            else:  # Gemini
                post_model = st.selectbox(
                    "ëª¨ë¸ ì„ íƒ",
                    options=[
                        "gemini-3-pro-preview",
                        "gemini-3-flash-preview"
                    ],
                    index=0,
                    help="í›„ì²˜ë¦¬ìš© Gemini ëª¨ë¸",
                    key="audio_post_model_gemini"
                )

        # í›„ì²˜ë¦¬ ë°©ì‹ ì„ íƒ
        gpt_mode = st.selectbox(
            "í›„ì²˜ë¦¬ ë°©ì‹",
            options=[
                ("ğŸ“ íšŒì˜ë¡ (3ì¤„ ìš”ì•½ + íƒ€ì„ë¼ì¸)", "meeting_summary"),
                ("ğŸ“Š Summary (í•µì‹¬ ìš”ì•½)", "summary"),
                ("ğŸ’¬ Q&A í˜•ì‹ (ì§ˆì˜ì‘ë‹µ)", "qa_format"),
                ("ğŸ“¢ ë°œí‘œìë£Œ í˜•ì‹ (í”„ë ˆì  í…Œì´ì…˜)", "presentation_format")
            ],
            format_func=lambda x: x[0],
            help="ì „ì‚¬ëœ ë‚´ìš©ì„ AIë¡œ ì¬êµ¬ì„± (ë¹„ìš© ì¶”ê°€ ë°œìƒ)",
            key="audio_gpt_mode_step3"
        )

        # í›„ì²˜ë¦¬ API í‚¤ ì…ë ¥ (ì „ì‚¬ ì—”ì§„ê³¼ ë‹¤ë¥¸ ê²½ìš°)
        post_api_key = None
        if post_engine[1] == "openai":
            # OpenAI í‚¤ê°€ í•„ìš”
            if 'transcription_api_key' in st.session_state and st.session_state.get('transcription_engine') == 'whisper':
                # ì „ì‚¬ì—ì„œ Whisperë¥¼ ì‚¬ìš©í–ˆìœ¼ë©´ í‚¤ ì¬ì‚¬ìš©
                post_api_key = st.session_state['transcription_api_key']
                st.info("â„¹ï¸ ì „ì‚¬ì— ì‚¬ìš©í•œ OpenAI API í‚¤ë¥¼ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.")
            else:
                # ìƒˆë¡œ ì…ë ¥ ë°›ê¸°
                post_api_key = st.text_input(
                    "OpenAI API Key (í›„ì²˜ë¦¬ìš©)",
                    type="password",
                    placeholder="sk-...",
                    key="audio_post_openai_key"
                )
        else:  # Gemini
            # Gemini í‚¤ê°€ í•„ìš”
            if 'transcription_api_key' in st.session_state and st.session_state.get('transcription_engine') == 'gemini':
                # ì „ì‚¬ì—ì„œ Geminië¥¼ ì‚¬ìš©í–ˆìœ¼ë©´ í‚¤ ì¬ì‚¬ìš©
                post_api_key = st.session_state['transcription_api_key']
                st.info("â„¹ï¸ ì „ì‚¬ì— ì‚¬ìš©í•œ Gemini API í‚¤ë¥¼ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.")
            else:
                # ìƒˆë¡œ ì…ë ¥ ë°›ê¸°
                post_api_key = st.text_input(
                    "Gemini API Key (í›„ì²˜ë¦¬ìš©)",
                    type="password",
                    placeholder="AI...",
                    key="audio_post_gemini_key"
                )

        # í›„ì²˜ë¦¬ ì‹¤í–‰ ë²„íŠ¼
        if st.button("ğŸ¤– AI í›„ì²˜ë¦¬ ì‹œì‘", use_container_width=True, type="secondary", key="audio_gpt_process_btn"):
            if not post_api_key:
                st.error("âš ï¸ API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤")
            else:
                with st.spinner(f"ğŸ¤– {post_engine[0]} í›„ì²˜ë¦¬ ì¤‘..."):
                    try:
                        # í˜„ì¬ í¸ì§‘ëœ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
                        current_text = st.session_state.get('audio_result_text', result_text)

                        # AI í›„ì²˜ë¦¬ ì‹¤í–‰
                        processed_text = utils_audio._gpt_postprocess(
                            raw_text=current_text,
                            mode=gpt_mode[1],
                            model=post_model,
                            api_key=post_api_key,
                            api_type=post_engine[1]
                        )

                        # ê²°ê³¼ë¥¼ ìƒˆë¡œìš´ ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ì— ì €ì¥
                        st.session_state['gpt_processed_result'] = processed_text
                        st.success(f"âœ… {post_engine[0]} í›„ì²˜ë¦¬ ì™„ë£Œ!")
                        st.rerun()
                    except Exception as e:
                        st.error(f"âš ï¸ í›„ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

        # GPT í›„ì²˜ë¦¬ ê²°ê³¼ í‘œì‹œ
        if 'gpt_processed_result' in st.session_state and st.session_state['gpt_processed_result']:
            st.markdown("#### ğŸ“Š GPT í›„ì²˜ë¦¬ ê²°ê³¼")
            with st.container(border=True):
                st.markdown(st.session_state['gpt_processed_result'])

            # GPT ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
            col_gpt_download1, col_gpt_download2 = st.columns(2)
            with col_gpt_download1:
                st.download_button(
                    label="ğŸ“¥ í›„ì²˜ë¦¬ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (TXT)",
                    data=st.session_state['gpt_processed_result'],
                    file_name=f"processed_{uploaded_audio.name.split('.')[0] if uploaded_audio else 'result'}.txt",
                    mime="text/plain",
                    use_container_width=True
                )
            with col_gpt_download2:
                st.download_button(
                    label="ğŸ“¥ í›„ì²˜ë¦¬ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (MD)",
                    data=st.session_state['gpt_processed_result'],
                    file_name=f"processed_{uploaded_audio.name.split('.')[0] if uploaded_audio else 'result'}.md",
                    mime="text/markdown",
                    use_container_width=True
                )

        # ============================================
        # ë‹¤ìš´ë¡œë“œ & ì´ˆê¸°í™”
        # ============================================
        st.markdown("---")
        st.markdown("#### ğŸ’¾ íŒŒì¼ ì €ì¥")

        col1, col2, col3 = st.columns(3)
        with col1:
            st.download_button(
                label="ğŸ“¥ ì „ì‚¬ ê²°ê³¼ (TXT)",
                data=st.session_state.get('audio_result_text', result_text),
                file_name=f"transcription_{uploaded_audio.name.split('.')[0] if uploaded_audio else 'result'}.txt",
                mime="text/plain",
                use_container_width=True
            )
        with col2:
            st.download_button(
                label="ğŸ“¥ ì „ì‚¬ ê²°ê³¼ (MD)",
                data=st.session_state.get('audio_result_text', result_text),
                file_name=f"transcription_{uploaded_audio.name.split('.')[0] if uploaded_audio else 'result'}.md",
                mime="text/markdown",
                use_container_width=True
            )
        with col3:
            if st.button("ğŸ”„ ì´ˆê¸°í™”", use_container_width=True, type="secondary"):
                # ëª¨ë“  ê´€ë ¨ ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ ì´ˆê¸°í™”
                if 'transcription_result' in st.session_state:
                    del st.session_state['transcription_result']
                if 'gpt_processed_result' in st.session_state:
                    del st.session_state['gpt_processed_result']
                if 'audio_result_text' in st.session_state:
                    del st.session_state['audio_result_text']
                st.rerun()
