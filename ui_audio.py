"""
ì˜¤ë””ì˜¤ ì „ì‚¬ ê¸°ëŠ¥ ë…ë¦½ ëª¨ë“ˆ
Whisper APIë¥¼ ì‚¬ìš©í•œ ìŒì„± íŒŒì¼ í…ìŠ¤íŠ¸ ë³€í™˜
"""
import streamlit as st
import utils_audio

def render_audio_transcription_panel():
    """ì˜¤ë””ì˜¤ ì „ì‚¬ ì „ìš© UI íŒ¨ë„"""
    st.markdown("### ğŸ¤ ì˜¤ë””ì˜¤ ì „ì‚¬ (Audio Transcription)")
    st.markdown("""
        <div style='background-color: #e8f4f8; padding: 12px; border-radius: 6px; margin-bottom: 15px;'>
        <b>ğŸ”Š ìŒì„± íŒŒì¼ ì „ì‚¬ ê¸°ëŠ¥ (ê³ ê¸‰)</b><br/>
        âœ“ Apple m4a íŒŒì¼ ì§€ì› (iPhone/iPad ë…¹ìŒ)<br/>
        âœ“ ê¸´ íŒŒì¼ ìë™ ë¶„í•  (FFmpeg í•„ìš”)<br/>
        âœ“ íƒ€ì„ìŠ¤íƒ¬í”„ & ë¬¸ë‹¨ ì •ë¦¬<br/>
        âœ“ GPT í›„ì²˜ë¦¬ (ìš”ì•½/ì •ë¦¬)
        </div>
    """, unsafe_allow_html=True)

    # API í‚¤ ì…ë ¥
    query_params = st.query_params
    cached_openai_key = query_params.get("openai_api_key", "")
    if isinstance(cached_openai_key, list):
        cached_openai_key = cached_openai_key[0]

    col1, col2 = st.columns([3, 1])
    with col1:
        openai_api_key = st.text_input(
            "OpenAI API Key",
            value=cached_openai_key,
            type="password",
            placeholder="sk-...",
            key="audio_openai_key"
        )
    with col2:
        st.write("")
        st.write("")
        save_key = st.checkbox("ğŸ”‘ í‚¤ ì €ì¥", value=bool(cached_openai_key), key="audio_save_key")

    if save_key and openai_api_key:
        st.query_params["openai_api_key"] = openai_api_key
    elif not save_key and "openai_api_key" in st.query_params:
        del st.query_params["openai_api_key"]

    # íŒŒì¼ ì—…ë¡œë“œ
    st.markdown("##### ì˜¤ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ")
    uploaded_audio = st.file_uploader(
        "MP3, WAV, M4A ë“± ì˜¤ë””ì˜¤ íŒŒì¼ ì„ íƒ",
        type=['mp3', 'wav', 'm4a', 'mp4', 'mpeg', 'mpga', 'webm', 'ogg', 'flac'],
        key="audio_file_uploader"
    )

    # ì „ì‚¬ ì˜µì…˜
    st.markdown("##### âš™ï¸ ì „ì‚¬ ì˜µì…˜")

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("**ê¸°ë³¸ ì„¤ì •**")
        include_timestamps = st.checkbox(
            "â±ï¸ íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨ [mm:ss]",
            value=True,
            help="ê° ë¬¸ë‹¨ì— ì‹œì‘-ì¢…ë£Œ ì‹œê°„ í‘œì‹œ",
            key="audio_timestamps"
        )

        remove_fillers = st.checkbox(
            "ğŸ§¹ ì¶”ì„ìƒˆ ìë™ ì œê±°",
            value=True,
            help="'ì•„', 'ìŒ', 'ê·¸' ë“± ë¶ˆí•„ìš”í•œ í‘œí˜„ ì œê±°",
            key="audio_remove_fillers"
        )

        chunk_minutes = st.slider(
            "ğŸ“¦ ê¸´ íŒŒì¼ ë¶„í•  ë‹¨ìœ„ (ë¶„)",
            min_value=5,
            max_value=30,
            value=10,
            step=5,
            help="FFmpeg ì„¤ì¹˜ ì‹œ ìë™ ë¶„í•  (ë¯¸ì„¤ì¹˜ ì‹œ ì „ì²´ ì²˜ë¦¬)",
            key="audio_chunk_minutes"
        )

    with col2:
        st.markdown("**ê³ ê¸‰ ì„¤ì •**")

        gpt_mode = st.selectbox(
            "ğŸ¤– GPT í›„ì²˜ë¦¬",
            options=[
                ("ì—†ìŒ", None),
                ("í…ìŠ¤íŠ¸ ì •ë¦¬", "clean"),
                ("íšŒì˜ë¡ ìš”ì•½", "summary"),
                ("ì§ˆì ì½”ë”©ìš©", "atlas_codebook")
            ],
            format_func=lambda x: x[0],
            help="ì „ì‚¬ í›„ GPTë¡œ ì¶”ê°€ ì •ë¦¬ (ë¹„ìš© ì¶”ê°€ ë°œìƒ)",
            key="audio_gpt_mode"
        )

        gpt_model = st.selectbox(
            "GPT ëª¨ë¸",
            options=["gpt-4o-mini", "gpt-4o", "gpt-4-turbo"],
            index=0,
            help="í›„ì²˜ë¦¬ìš© ëª¨ë¸ ì„ íƒ",
            key="audio_gpt_model"
        )

        # í™”ì ë¶„ë¦¬ (ê³ ê¸‰ ê¸°ëŠ¥ - HF_TOKEN í•„ìš”)
        do_diarization = st.checkbox(
            "ğŸ­ í™”ì ë¶„ë¦¬ ì‹œë„ (ì‹¤í—˜ì )",
            value=False,
            help="HuggingFace Token í™˜ê²½ë³€ìˆ˜ í•„ìš” (HF_TOKEN)",
            key="audio_diarization"
        )

    # FFmpeg ì„¤ì¹˜ í™•ì¸
    has_ffmpeg = utils_audio._has_ffmpeg()
    if not has_ffmpeg:
        st.warning("âš ï¸ FFmpegê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸´ íŒŒì¼ ë¶„í•  ë° í˜•ì‹ ë³€í™˜ì´ ì œí•œë©ë‹ˆë‹¤.")

    # ì „ì‚¬ ì‹¤í–‰
    if st.button("ğŸš€ ì „ì‚¬ ì‹œì‘", use_container_width=True, type="primary", key="audio_transcribe_btn"):
        if not openai_api_key:
            st.error("âš ï¸ OpenAI API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”")
        elif not uploaded_audio:
            st.error("âš ï¸ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”")
        else:
            with st.spinner("ğŸ§ ì˜¤ë””ì˜¤ ì „ì‚¬ ì¤‘... (íŒŒì¼ í¬ê¸°ì— ë”°ë¼ ìˆ˜ ë¶„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)"):
                transcribed_text = utils_audio.transcribe_audio(
                    uploaded_file=uploaded_audio,
                    api_key=openai_api_key,
                    language="ko",
                    chunk_seconds=chunk_minutes * 60,
                    do_diarization=do_diarization,
                    include_timestamps=include_timestamps,
                    remove_fillers=remove_fillers,
                    gpt_mode=gpt_mode[1],  # tupleì˜ ë‘ ë²ˆì§¸ ê°’ (ì‹¤ì œ mode)
                    gpt_model=gpt_model
                )

                # ê²°ê³¼ ì €ì¥
                st.session_state['transcription_result'] = transcribed_text
                st.success("âœ… ì „ì‚¬ ì™„ë£Œ!")

    # ê²°ê³¼ í‘œì‹œ
    if 'transcription_result' in st.session_state and st.session_state['transcription_result']:
        st.markdown("---")
        st.markdown("### ğŸ“ ì „ì‚¬ ê²°ê³¼")

        result_text = st.session_state['transcription_result']

        # ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° (ë§ˆí¬ë‹¤ìš´ ë Œë”ë§)
        with st.expander("ğŸ“„ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°", expanded=True):
            st.markdown(result_text)

        # í¸ì§‘ ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ ì˜ì—­
        st.markdown("##### í¸ì§‘ ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸")
        edited_text = st.text_area(
            "ì „ì‚¬ëœ í…ìŠ¤íŠ¸ (í¸ì§‘ ê°€ëŠ¥)",
            value=result_text,
            height=400,
            key="audio_result_text"
        )

        # ë‹¤ìš´ë¡œë“œ ë° ì´ˆê¸°í™” ë²„íŠ¼
        col1, col2, col3 = st.columns(3)
        with col1:
            st.download_button(
                label="ğŸ“¥ í…ìŠ¤íŠ¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                data=edited_text,
                file_name=f"transcription_{uploaded_audio.name.split('.')[0]}.txt",
                mime="text/plain",
                use_container_width=True
            )
        with col2:
            st.download_button(
                label="ğŸ“¥ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                data=edited_text,
                file_name=f"transcription_{uploaded_audio.name.split('.')[0]}.md",
                mime="text/markdown",
                use_container_width=True
            )
        with col3:
            if st.button("ğŸ”„ ì´ˆê¸°í™”", use_container_width=True):
                del st.session_state['transcription_result']
                st.rerun()
