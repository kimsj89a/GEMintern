import streamlit as st
import os
import sys
import subprocess

def render_crawler_panel(settings):
    """ì›¹ í¬ë¡¤ëŸ¬ UI íŒ¨ë„"""
    st.markdown("### ğŸŒ ì›¹ ì‚¬ì´íŠ¸ í¬ë¡¤ëŸ¬ (Web Crawler)")
    
    # ì‚¬ìš©ì ì§€ì • ê²½ë¡œ
    crawler_path = r"C:\Users\kimsj\WebSiteCrawler"
    
    st.markdown(f"""
        <div style='background-color: #f0f2f6; padding: 15px; border-radius: 8px; margin-bottom: 20px; border-left: 4px solid #ff4b4b;'>
        <h4 style='margin-top: 0; color: #ff4b4b;'>ğŸ•·ï¸ WebSiteCrawler ì—°ë™</h4>
        <b>ì§€ì • ê²½ë¡œ:</b> <code>{crawler_path}</code><br/>
        ì™¸ë¶€ í¬ë¡¤ëŸ¬ í”„ë¡œì íŠ¸ë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ í†µí•©í•©ë‹ˆë‹¤.
        </div>
    """, unsafe_allow_html=True)

    # íƒ­ êµ¬ì„±
    tab_run, tab_view = st.tabs(["ğŸš€ í¬ë¡¤ë§ ì‹¤í–‰", "ğŸ“Š ê²°ê³¼ ë¶„ì„"])

    with tab_run:
        st.markdown("#### í¬ë¡¤ë§ íŒŒë¼ë¯¸í„° ì„¤ì •")
        
        col1, col2 = st.columns([3, 1])
        with col1:
            target_url = st.text_input("Target URL", placeholder="https://www.example.com")
        with col2:
            depth = st.number_input("Depth", min_value=1, max_value=10, value=1)
            
        if st.button("ğŸ•·ï¸ í¬ë¡¤ë§ ì‹œì‘", use_container_width=True, type="primary"):
            if not os.path.exists(crawler_path):
                st.error(f"âŒ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {crawler_path}")
                st.warning("í•´ë‹¹ ê²½ë¡œì— í¬ë¡¤ëŸ¬ í”„ë¡œì íŠ¸ í´ë”ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
            elif not target_url:
                st.warning("âš ï¸ URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                st.info(f"ğŸ“¡ '{target_url}' í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤... (ê²½ë¡œ: {crawler_path})")
                
                # [TODO] ì‹¤ì œ í¬ë¡¤ëŸ¬ ì‹¤í–‰ ë¡œì§ ì—°ê²°
                # ì˜ˆì‹œ: subprocessë¡œ main.py ì‹¤í–‰ (íŒŒì¼ëª…ì— ë§ê²Œ ìˆ˜ì • í•„ìš”)
                # try:
                #     # ê°€ìƒí™˜ê²½ì´ë‚˜ python ì‹¤í–‰ ëª…ë ¹ì–´ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”
                #     result = subprocess.run(
                #         ["python", os.path.join(crawler_path, "main.py"), "--url", target_url, "--depth", str(depth)],
                #         capture_output=True, text=True, cwd=crawler_path
                #     )
                #     if result.returncode == 0:
                #         st.success("í¬ë¡¤ë§ ì™„ë£Œ!")
                #         st.code(result.stdout)
                #     else:
                #         st.error(f"ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:\n{result.stderr}")
                # except Exception as e:
                #     st.error(f"ì‹¤í–‰ ì˜¤ë¥˜: {e}")
                
                st.warning("âš ï¸ í˜„ì¬ëŠ” UIë§Œ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤. `ui_crawler.py` íŒŒì¼ì˜ ì£¼ì„ì„ í•´ì œí•˜ì—¬ ì‹¤ì œ ì‹¤í–‰ ë¡œì§(subprocess ë“±)ì„ í™œì„±í™”í•´ì£¼ì„¸ìš”.")

    with tab_view:
        st.markdown("#### ìˆ˜ì§‘ ë°ì´í„° ë·°ì–´")
        st.info("í¬ë¡¤ë§ ì™„ë£Œ í›„ ì €ì¥ëœ ë°ì´í„°(CSV/JSON)ë¥¼ ì´ê³³ì— í‘œì‹œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")