from google import genai
from google.genai import types

# --- RFI ì „ìš© í”„ë¡¬í”„íŠ¸ ---
PROMPTS = {
    'indexing': """
ë‹¹ì‹ ì€ ìë£Œ ê´€ë¦¬ ë° ì¸ë±ì‹± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
[ê¸°ì¡´ ìš”ì²­ ìë£Œ ëª©ë¡(RFI)]ê³¼ [ìˆ˜ë ¹í•œ íŒŒì¼ ëª©ë¡]ì„ ëŒ€ì¡°í•˜ì—¬ ì œì¶œ í˜„í™©ì„ ì ê²€í•˜ì‹­ì‹œì˜¤.

# Task
1. ì‚¬ìš©ìê°€ ì œì¶œí•œ **íŒŒì¼ëª…ë“¤ì„ ë¶„ì„**í•˜ì—¬, ê¸°ì¡´ RFI í•­ëª© ì¤‘ ì–´ëŠ ê²ƒì— í•´ë‹¹í•˜ëŠ”ì§€ ë§¤ì¹­í•˜ì‹­ì‹œì˜¤.
2. ê° í•­ëª©ì˜ ì œì¶œ ìƒíƒœë¥¼ ì•„ë˜ ê¸°ì¤€ìœ¼ë¡œ íŒë³„í•˜ì‹­ì‹œì˜¤.
   - **O (ì œì¶œë¨)**: íŒŒì¼ëª…ìœ¼ë¡œ ë³´ì•„ í•´ë‹¹ ìë£Œê°€ ëª…í™•íˆ í¬í•¨ë¨.
   - **â–³ (í™•ì¸ í•„ìš”)**: íŒŒì¼ëª…ì´ ëª¨í˜¸í•˜ê±°ë‚˜, ë¶€ë¶„ì ìœ¼ë¡œë§Œ í¬í•¨ëœ ê²ƒìœ¼ë¡œ ì¶”ì •ë¨.
   - **X (ë¯¸ì œì¶œ)**: í•´ë‹¹ ë‚´ìš©ì„ ìœ ì¶”í•  ìˆ˜ ìˆëŠ” íŒŒì¼ì´ ì—†ìŒ.
3. ê²°ê³¼ëŠ” ë°˜ë“œì‹œ **Markdown Table** í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤. ì„¤ëª…ì€ í•„ìš” ì—†ìŠµë‹ˆë‹¤.

# Output Table Format
| No. | êµ¬ë¶„ | ê¸°ì¡´ ìš”ì²­ ìë£Œ | ë§¤ì¹­ëœ íŒŒì¼ëª…(ì—†ìœ¼ë©´ -) | ìƒíƒœ(O/â–³/X) | ë¹„ê³  |
| --- | --- | --- | --- | --- | --- |
""",
    'finalizing': """
ë‹¹ì‹ ì€ íšŒê³„ë²•ì¸ FASíŒ€ì˜ **M&A ì‹¤ì‚¬(Due Diligence) ì „ë¬¸ ë§¤ë‹ˆì €**ì…ë‹ˆë‹¤.
[1ì°¨ ìë£Œ ì ê²€ ê²°ê³¼]ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ë¶€ì¡±í•œ ìë£Œë¥¼ íŒŒì•…í•˜ê³  **ìµœì¢… RFI(ìë£Œìš”ì²­ëª©ë¡)**ë¥¼ ì‘ì„±í•˜ì‹­ì‹œì˜¤.

# Context: [ê¸°ë³¸ ì‹¤ì‚¬ ì²´í¬ë¦¬ìŠ¤íŠ¸]
ì•„ë˜ í•„ìˆ˜ í•­ëª©ë“¤ì´ ëˆ„ë½ë˜ì—ˆë‹¤ë©´ ë°˜ë“œì‹œ ì¶”ê°€ ìš”ì²­í•´ì•¼ í•©ë‹ˆë‹¤.
1. íšŒì‚¬ì¼ë°˜: ì£¼ì£¼ëª…ë¶€, ì •ê´€, ë“±ê¸°ë¶€ë“±ë³¸, ì¡°ì§ë„
2. ì¬ë¬´/íšŒê³„: ìµœê·¼ 3ê°œë…„ ê°ì‚¬ë³´ê³ ì„œ, ê³„ì •ë³„ ì›ì¥, ì›”ë³„ ê²°ì‚°ì„œ
3. ì˜ì—…/ì‹œì¥: ì£¼ìš” ë§¤ì¶œì²˜ ê³„ì•½ì„œ, ìˆ˜ì£¼ì”ê³ , ì‹œì¥ M/S ìë£Œ
4. ì¸ì‚¬/ë…¸ë¬´: ê¸‰ì—¬ëŒ€ì¥, í‡´ì§ê¸ˆ ì¶”ê³„ì•¡, ì¡°ì§ë„
5. ë²•ë¬´: ì†Œì†¡ í˜„í™©, ì œì¬ ë‚´ì—­

# Task
1. **[1. ê¸°ì¡´ ìë£Œ ì œì¶œ í˜„í™©]**: ì•ì„œ ìƒì„±ëœ 'ì ê²€ ê²°ê³¼ í‘œ'ë¥¼ ë‹¤ë“¬ì–´ì„œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤. (ìƒíƒœê°€ Xì¸ í•­ëª© ê°•ì¡°)
2. **[2. ì¶”ê°€ ìš”ì²­ ì‚¬í•­]**: 
   - ìƒíƒœê°€ **X** ë˜ëŠ” **â–³**ì¸ í•­ëª©ì„ ë‹¤ì‹œ ìš”ì²­ ë¦¬ìŠ¤íŠ¸ì— í¬í•¨í•˜ì‹­ì‹œì˜¤.
   - [ê¸°ë³¸ ì‹¤ì‚¬ ì²´í¬ë¦¬ìŠ¤íŠ¸] ì¤‘ ì•„ì˜ˆ ì–¸ê¸‰ë˜ì§€ ì•Šì€ í•„ìˆ˜ ìë£Œë¥¼ ì¶”ê°€í•˜ì‹­ì‹œì˜¤.
   - ì‚¬ìš©ìì˜ [ì¶”ê°€ ì§ˆë¬¸/ë§¥ë½]ì„ ë°˜ì˜í•˜ì—¬ êµ¬ì²´ì ì¸ ìë£Œë¥¼ ìš”ì²­í•˜ì‹­ì‹œì˜¤.

# Output Style
- í‘œ í˜•ì‹ì„ ì‚¬ìš©í•˜ì—¬ ê¹”ë”í•˜ê²Œ ì •ë¦¬í•˜ì‹­ì‹œì˜¤.
- ë¶ˆí•„ìš”í•œ ì„œë¡ /ê²°ë¡  ì—†ì´ í‘œì™€ í•µì‹¬ ì½”ë©˜íŠ¸ ìœ„ì£¼ë¡œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
"""
}

def get_client(api_key):
    return genai.Client(api_key=api_key)

def extract_filenames_from_objects(uploaded_files):
    """
    Streamlit UploadedFile ê°ì²´ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì´ë¦„ë§Œ ì¶”ì¶œ.
    íŒŒì¼ ë‚´ìš©(Bytes)ì€ ì ˆëŒ€ ì½ì§€ ì•Šìœ¼ë¯€ë¡œ ì„œë²„ ë¶€í•˜ ì—†ìŒ.
    """
    if not uploaded_files:
        return "(ìˆ˜ë ¹í•œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤)"
    
    # ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜ìœ¼ë¡œ ì´ë¦„ë§Œ ë¹ ë¥´ê²Œ ì¶”ì¶œ
    return "\n".join([f"- {f.name}" for f in uploaded_files])

def analyze_rfi_status(client, existing_rfi, file_list_str):
    """Step 1: Flash ëª¨ë¸ë¡œ ì¸ë±ì‹±"""
    prompt = f"""
    {PROMPTS['indexing']}
    
    [ê¸°ì¡´ ìš”ì²­ ìë£Œ ëª©ë¡(RFI)]
    {existing_rfi}
    
    [ìˆ˜ë ¹í•œ íŒŒì¼ ëª©ë¡ (íŒŒì¼ëª… ì¸ë±ìŠ¤)]
    {file_list_str}
    """
    try:
        resp = client.models.generate_content(
            model="gemini-2.0-flash-exp", 
            contents=prompt,
            config=types.GenerateContentConfig(temperature=0.1)
        )
        return resp.text
    except Exception as e:
        return f"ì¸ë±ì‹± ì˜¤ë¥˜: {str(e)}"

def generate_rfi_stream(api_key, model_name, inputs, thinking_level):
    """RFI ìƒì„± ë©”ì¸ ë¡œì§ (ìŠ¤íŠ¸ë¦¬ë°)"""
    client = get_client(api_key)
    
    # 1. íŒŒì¼ ëª©ë¡ ì¤€ë¹„ (Standard Uploader -> Name Extraction)
    file_list_str = extract_filenames_from_objects(inputs['uploaded_files'])
    
    # UI ì•Œë¦¼
    yield types.GenerateContentResponse(
        candidates=[types.Candidate(
            content=types.Content(parts=[types.Part(text="ğŸ“‚ [Step 1] ì—…ë¡œë“œëœ íŒŒì¼ëª… ìë™ ëŒ€ì‚¬(Indexing) ì§„í–‰ ì¤‘...\n\n")])
        )]
    )
    
    # 2. Step 1: ì¸ë±ì‹± (Flash)
    rfi_status_table = analyze_rfi_status(client, inputs['rfi_existing'], file_list_str)
    
    yield types.GenerateContentResponse(
        candidates=[types.Candidate(
            content=types.Content(parts=[types.Part(text=f"{rfi_status_table}\n\n---\nğŸ§  [Step 2] ë¶€ì¡± ìë£Œ ë¶„ì„ ë° ìµœì¢… RFI ì‘ì„± ì¤‘... ({model_name})\n\n")])
        )]
    )

    # 3. Step 2: ìµœì¢… RFI ì‘ì„± (Main Model)
    main_prompt = f"""
    [System: Thinking Level {thinking_level.upper() if isinstance(thinking_level, str) else 'HIGH'}]
    
    [1ì°¨ ìë£Œ ì ê²€ ê²°ê³¼ (íŒŒì¼ëª… ë¶„ì„)]
    {rfi_status_table}

    [ì‚¬ìš©ì ì¶”ê°€ ì§ˆë¬¸/ë§¥ë½]
    {inputs['context_text']}
    """
    
    config = types.GenerateContentConfig(
        max_output_tokens=8192,
        temperature=0.2, 
        system_instruction=PROMPTS['finalizing']
    )
    
    response_stream = client.models.generate_content_stream(
        model=model_name,
        contents=main_prompt,
        config=config
    )
    
    for chunk in response_stream:
        yield chunk