import os
import datetime
from google import genai
from google.genai import types

# --- RFI ì „ìš© í”„ë¡¬í”„íŠ¸ ---
PROMPTS = {
    'indexing': """
ë‹¹ì‹ ì€ ìë£Œ ê´€ë¦¬ ë° ì¸ë±ì‹± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
[ê¸°ì¡´ ìš”ì²­ ìë£Œ ëª©ë¡(RFI)]ê³¼ [ìˆ˜ë ¹í•œ íŒŒì¼ ì¸ë±ìŠ¤(Local Scan)]ë¥¼ ëŒ€ì¡°í•˜ì—¬ ì œì¶œ í˜„í™©ì„ ì ê²€í•˜ì‹­ì‹œì˜¤.

# Task
1. ì‚¬ìš©ìê°€ ìŠ¤ìº”í•œ **íŒŒì¼ ê²½ë¡œ ë° ë©”íƒ€ë°ì´í„°**ë¥¼ ë¶„ì„í•˜ì—¬, ê¸°ì¡´ RFI í•­ëª© ì¤‘ ì–´ëŠ ê²ƒì— í•´ë‹¹í•˜ëŠ”ì§€ ë§¤ì¹­í•˜ì‹­ì‹œì˜¤.
2. ê° í•­ëª©ì˜ ì œì¶œ ìƒíƒœë¥¼ ì•„ë˜ ê¸°ì¤€ìœ¼ë¡œ íŒë³„í•˜ì‹­ì‹œì˜¤.
   - **O (ì œì¶œë¨)**: íŒŒì¼ëª…ìœ¼ë¡œ ë³´ì•„ í•´ë‹¹ ìë£Œê°€ ëª…í™•íˆ í¬í•¨ë¨.
   - **â–³ (í™•ì¸ í•„ìš”)**: íŒŒì¼ëª…ì´ ëª¨í˜¸í•˜ê±°ë‚˜, ë¶€ë¶„ì ìœ¼ë¡œë§Œ í¬í•¨ëœ ê²ƒìœ¼ë¡œ ì¶”ì •ë¨.
   - **X (ë¯¸ì œì¶œ)**: í•´ë‹¹ ë‚´ìš©ì„ ìœ ì¶”í•  ìˆ˜ ìˆëŠ” íŒŒì¼ì´ ì—†ìŒ.
3. ê²°ê³¼ëŠ” ë°˜ë“œì‹œ **Markdown Table** í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤. ì„¤ëª…ì€ í•„ìš” ì—†ìŠµë‹ˆë‹¤.

# Output Table Format
| No. | êµ¬ë¶„ | ê¸°ì¡´ ìš”ì²­ ìë£Œ | ë§¤ì¹­ëœ íŒŒì¼ ì •ë³´(ê²½ë¡œ/í¬ê¸°/ë‚ ì§œ) | ìƒíƒœ(O/â–³/X) | ë¹„ê³  |
| --- | --- | --- | --- | --- | --- |
""",
    'finalizing': """
ë‹¹ì‹ ì€ íšŒê³„ë²•ì¸ FASíŒ€ì˜ **M&A ì‹¤ì‚¬(Due Diligence) ì „ë¬¸ ë§¤ë‹ˆì €**ì…ë‹ˆë‹¤.
[1ì°¨ ìë£Œ ì ê²€ ê²°ê³¼]ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ë¶€ì¡±í•œ ìë£Œë¥¼ íŒŒì•…í•˜ê³  **ìµœì¢… RFI(ìë£Œìš”ì²­ëª©ë¡)**ë¥¼ ì‘ì„±í•˜ì‹­ì‹œì˜¤.

# Task
1. **[1. ê¸°ì¡´ ìë£Œ ì œì¶œ í˜„í™©]**: ì•ì„œ ìƒì„±ëœ 'ì ê²€ ê²°ê³¼ í‘œ'ë¥¼ ë‹¤ë“¬ì–´ì„œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤.
2. **[2. ì¶”ê°€ ìš”ì²­ ì‚¬í•­]**: 
   - ìƒíƒœê°€ **X** ë˜ëŠ” **â–³**ì¸ í•­ëª©ì„ ë‹¤ì‹œ ìš”ì²­ ë¦¬ìŠ¤íŠ¸ì— í¬í•¨í•˜ì‹­ì‹œì˜¤.
   - [ê¸°ë³¸ ì‹¤ì‚¬ ì²´í¬ë¦¬ìŠ¤íŠ¸] ì¤‘ ì•„ì˜ˆ ì–¸ê¸‰ë˜ì§€ ì•Šì€ í•„ìˆ˜ ìë£Œë¥¼ ì¶”ê°€í•˜ì‹­ì‹œì˜¤.

# Output Style
- í‘œ í˜•ì‹ì„ ì‚¬ìš©í•˜ì—¬ ê¹”ë”í•˜ê²Œ ì •ë¦¬í•˜ì‹­ì‹œì˜¤.
"""
}

def get_client(api_key):
    return genai.Client(api_key=api_key)

def index_local_directory(start_path):
    """
    [User Request] os.walkë¥¼ í™œìš©í•œ ë¡œì»¬ ë””ë ‰í† ë¦¬ ì¸ë±ì‹±
    """
    if not os.path.exists(start_path):
        return f"Error: ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ({start_path})"

    file_index_str = "| íŒŒì¼ëª… | ê²½ë¡œ | í¬ê¸°(KB) | ìˆ˜ì •ì¼ |\n|---|---|---|---|\n"
    count = 0

    try:
        for dirpath, dirnames, filenames in os.walk(start_path):
            for filename in filenames:
                full_path = os.path.join(dirpath, filename)
                try:
                    stat_info = os.stat(full_path)
                    size_kb = round(stat_info.st_size / 1024, 1)
                    mtime = datetime.datetime.fromtimestamp(stat_info.st_mtime).strftime('%Y-%m-%d')
                    
                    # ì ˆëŒ€ ê²½ë¡œì—ì„œ ì…ë ¥ëœ ì‹œì‘ ê²½ë¡œë§Œí¼ ì˜ë¼ë‚´ì–´ ìƒëŒ€ ê²½ë¡œì²˜ëŸ¼ í‘œì‹œ (ê°€ë…ì„±)
                    display_path = full_path.replace(start_path, '').replace('\\', '/')
                    if display_path.startswith('/'): display_path = display_path[1:]

                    file_index_str += f"| {filename} | {display_path} | {size_kb}KB | {mtime} |\n"
                    count += 1
                except OSError:
                    continue
    except Exception as e:
        return f"ì¸ë±ì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

    if count == 0:
        return "í•´ë‹¹ ê²½ë¡œì— íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."
    
    return file_index_str

def analyze_rfi_status(client, existing_rfi, file_index_str):
    """Step 1: Flash ëª¨ë¸ë¡œ ì¸ë±ì‹±"""
    prompt = f"""
    {PROMPTS['indexing']}
    
    [ê¸°ì¡´ ìš”ì²­ ìë£Œ ëª©ë¡(RFI)]
    {existing_rfi}
    
    [ìˆ˜ë ¹í•œ íŒŒì¼ ì¸ë±ìŠ¤ (Local OS Scan)]
    {file_index_str}
    """
    try:
        resp = client.models.generate_content(
            model="gemini-2.0-flash-exp", 
            contents=prompt,
            config=types.GenerateContentConfig(temperature=0.1)
        )
        return resp.text
    except Exception as e:
        return f"ì¸ë±ì‹± ì˜¤ë¥˜: {str(e)}"

def generate_rfi_stream(api_key, model_name, inputs, thinking_level):
    """RFI ìƒì„± ë©”ì¸ ë¡œì§ (ìŠ¤íŠ¸ë¦¬ë°)"""
    client = get_client(api_key)
    
    # 1. íŒŒì¼ ëª©ë¡ (ì´ë¯¸ UIì—ì„œ ì¸ë±ì‹±ëœ í…ìŠ¤íŠ¸ë¥¼ ë°›ìŒ)
    file_index_str = inputs.get('rfi_file_list_input', '')
    if not file_index_str:
        file_index_str = "(íŒŒì¼ ì¸ë±ìŠ¤ ì—†ìŒ)"
    
    # UI ì•Œë¦¼
    yield types.GenerateContentResponse(
        candidates=[types.Candidate(
            content=types.Content(parts=[types.Part(text="ğŸ“‚ [Step 1] ë¡œì»¬ ì¸ë±ìŠ¤ ê¸°ë°˜ ëŒ€ì‚¬(Indexing) ì§„í–‰ ì¤‘...\n\n")])
        )]
    )
    
    # 2. Step 1: ì¸ë±ì‹± (Flash)
    rfi_status_table = analyze_rfi_status(client, inputs['rfi_existing'], file_index_str)
    
    yield types.GenerateContentResponse(
        candidates=[types.Candidate(
            content=types.Content(parts=[types.Part(text=f"{rfi_status_table}\n\n---\nğŸ§  [Step 2] ë¶€ì¡± ìë£Œ ë¶„ì„ ë° ìµœì¢… RFI ì‘ì„± ì¤‘... ({model_name})\n\n")])
        )]
    )

    # 3. Step 2: ìµœì¢… RFI ì‘ì„± (Main Model)
    main_prompt = f"""
    [System: Thinking Level {thinking_level.upper() if isinstance(thinking_level, str) else 'HIGH'}]
    
    [1ì°¨ ìë£Œ ì ê²€ ê²°ê³¼]
    {rfi_status_table}

    [ì‚¬ìš©ì ì¶”ê°€ ì§ˆë¬¸/ë§¥ë½]
    {inputs['context_text']}
    """
    
    config = types.GenerateContentConfig(
        max_output_tokens=8192,
        temperature=0.2, 
        system_instruction=PROMPTS['finalizing']
    )
    
    response_stream = client.models.generate_content_stream(
        model=model_name,
        contents=main_prompt,
        config=config
    )
    
    for chunk in response_stream:
        yield chunk